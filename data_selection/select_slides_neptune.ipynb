{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.utils_constants'; 'utils' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Import constants and utility functions from utils module.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     NEPTUNE_PAT_INFO_PATH \u001b[38;5;28;01mas\u001b[39;00m PAT_INFO_PATH,\n\u001b[1;32m     20\u001b[0m     NEPTUNE_WSI_INFO_PATH \u001b[38;5;28;01mas\u001b[39;00m WSI_INFO_PATH,\n\u001b[1;32m     21\u001b[0m     VESSEL_NEPTUNE_PAT_INFO_PATH,\n\u001b[1;32m     22\u001b[0m     VESSEL_SEGMENTATION_REF_PATH,\n\u001b[1;32m     23\u001b[0m     INNER_SEGMENTATION_REF_DIR,\n\u001b[1;32m     24\u001b[0m     TRI_CASE_DIR\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Configure logging to help track application behavior and debug issues.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.utils_constants'; 'utils' is not a package"
     ]
    }
   ],
   "source": [
    "# Basic imports and configuration for the project.\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "from util import (\n",
    "    identify_wsi_based_on_prefix,\n",
    "    update_flag_and_check_missing,\n",
    "    get_wsi_files_by_biopsy_id_and_stain,\n",
    "    check_if_file_exists,\n",
    "    check_if_file_openable\n",
    ")\n",
    "\n",
    "# Extend the system path to include the parent directory for module imports.\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import constants and utility functions from utils module.\n",
    "from utils.utils_constants import (\n",
    "    NEPTUNE_PAT_INFO_PATH as PAT_INFO_PATH,\n",
    "    NEPTUNE_WSI_INFO_PATH as WSI_INFO_PATH,\n",
    "    VESSEL_NEPTUNE_PAT_INFO_PATH,\n",
    "    VESSEL_SEGMENTATION_REF_PATH,\n",
    "    INNER_SEGMENTATION_REF_DIR,\n",
    "    TRI_CASE_DIR\n",
    ")\n",
    "\n",
    "# Configure logging to help track application behavior and debug issues.\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the stain type used across this module.\n",
    "STAIN = \"TRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "pat_df = pd.read_csv(PAT_INFO_PATH)\n",
    "wsi_df = pd.read_excel(WSI_INFO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting cases in vessel segmentation task (Jayapandian & Chen, KI, 2020)\n",
    "seg_ref = pd.read_excel(VESSEL_SEGMENTATION_REF_PATH, skiprows=3)\n",
    "seg_ref = seg_ref[seg_ref[\"File_Name\"].notna() & seg_ref[STAIN].notna()]\n",
    "print(f\"Total {int(seg_ref[STAIN].sum())} Arteries Annotated in {STAIN} Stained {len(seg_ref)} Slides\")\n",
    "seg_prefixes = [s.strip().replace(\"-\", \"_\") for s in seg_ref[\"File_Name\"].tolist()]\n",
    "seg_biopsies, seg_biopsy_to_wsi_map = identify_wsi_based_on_prefix(wsi_df, seg_prefixes, STAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting cases in intra-arterial segmentation task (Zhou, JMI, 2024)\n",
    "inner_seg_prefixes = [x.replace(\".geojson\", \"\") for x in os.listdir(INNER_SEGMENTATION_REF_DIR) if x.endswith(\".geojson\")]\n",
    "inner_seg_biopsies, inner_seg_biopsy_to_wsi_map = identify_wsi_based_on_prefix(wsi_df, inner_seg_prefixes, STAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting cases in Tubule task (Fan)\n",
    "tubule_biopsies = set(wsi_df[wsi_df[\"USE_Tubule\"] == 1][\"biopsyid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the patient info to flag biopsies used in various tasks.\n",
    "# It also checks for any missing biopsies in the list.\n",
    "\n",
    "# Update and check for \"USE_Tubule\"\n",
    "pat_df = update_flag_and_check_missing(pat_df, tubule_biopsies, \"USE_Tubule\")\n",
    "\n",
    "# Update and check for \"Used_in_Vessel_Seg\"\n",
    "pat_df = update_flag_and_check_missing(pat_df, seg_biopsies, \"Used_in_Vessel_Seg\")\n",
    "\n",
    "# Update and check for \"Used_in_Inner_Structure_Seg\"\n",
    "pat_df = update_flag_and_check_missing(pat_df, inner_seg_biopsies, \"Used_in_Inner_Structure_Seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update clinical DataFrame with WSI file names for vessel and inner structure segmentation\n",
    "# Merge seg_biopsy_to_wsi_map and inner_seg_biopsy_to_wsi_map, with inner_seg_biopsy_to_wsi_map taking precedence in case of overlapping keys\n",
    "\n",
    "for biopsy_id, wsi_file in {**seg_biopsy_to_wsi_map, **inner_seg_biopsy_to_wsi_map}.items():\n",
    "    if biopsy_id in pat_df['BiopsyID'].values:\n",
    "        pat_df.loc[pat_df['BiopsyID'] == biopsy_id, 'WSI_Selected'] = wsi_file\n",
    "\n",
    "nonexistent_files = []\n",
    "# For additional biopsies, select a TRI file if not already assigned\n",
    "for biopsy_id in pat_df[\"BiopsyID\"].values:\n",
    "    # Check if 'WSI_Selected' is not null for the current biopsy_id\n",
    "    if not pat_df.loc[pat_df['BiopsyID'] == biopsy_id, 'WSI_Selected'].isnull().all():\n",
    "        continue  # Skip this iteration if WSI_Selected is already assigned\n",
    "    filenames = get_wsi_files_by_biopsy_id_and_stain(wsi_df, STAIN, biopsy_id)\n",
    "    for filename in filenames:\n",
    "        file_exists = check_if_file_exists(TRI_CASE_DIR, filename)\n",
    "        file_openable = file_exists and check_if_file_openable(TRI_CASE_DIR, filename)\n",
    "        if file_openable:\n",
    "            # Assign first openable file to WSI_Selected and stop checking further\n",
    "            pat_df.loc[pat_df['BiopsyID'] == biopsy_id, 'WSI_Selected'] = filename\n",
    "            break  # Found a suitable file, exit the loop\n",
    "        elif not file_exists:\n",
    "            # Assign the filename for further action but note it's nonexistent\n",
    "            pat_df.loc[pat_df['BiopsyID'] == biopsy_id, 'WSI_Selected'] = filename\n",
    "            nonexistent_files.append(filename)  # Keep track of nonexistent files\n",
    "            break  # Exit the loop after assignment\n",
    "        else:\n",
    "            # File exists but is not openable; print a message and continue checking other files\n",
    "            print(f\"Cannot open: {filename}\")\n",
    "            \n",
    "# Check if there are any nonexistent files recorded\n",
    "if nonexistent_files:\n",
    "    # Join the list of nonexistent files into a single string for better readability in the print statement\n",
    "    files_list_str = ', '.join(nonexistent_files)\n",
    "    print(f\"The following files need to be found and uploaded: {files_list_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming wsi_df DataFrame is updated with \"Used_in_Vessel_Seg\", \"Used_in_Inner_Structure_Seg\", \"USE_Tubule\", \"use_vessel\", and \"WSI_Selected\" columns\n",
    "\n",
    "# Calculate statistics\n",
    "total_biopsies = len(pat_df)\n",
    "used_in_vessel_seg = pat_df[\"Used_in_Vessel_Seg\"].sum()\n",
    "used_in_inner_seg = pat_df[\"Used_in_Inner_Structure_Seg\"].sum()\n",
    "files_assigned_w_clinical_info = pat_df[pat_df[\"WSI_Selected\"].notna()\n",
    "                                             & pat_df[\"ESRDorEGFR40BX_LR\"].notna()\n",
    "                                             & pat_df[\"DaysBXtoESRDorEGFR40_LR\"].notna()].shape[0]\n",
    "# Print the statistics\n",
    "print(f\"Total Biopsies: {total_biopsies}\")\n",
    "print(f\"Biopsies Used in Vessel Segmentation: {used_in_vessel_seg}\")\n",
    "print(f\"Biopsies Used in Inner Structure Segmentation: {used_in_inner_seg}\")\n",
    "print(f\"Biopsies with a File Assigned for Vessel Project: {files_assigned_w_clinical_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fake names for WSI (Whole Slide Images) selected for de-identification purposes.\n",
    "# 'Biopsy_index' is where the biopsy information is located. For example, 'Biopsy_001_WSI_001'.\n",
    "# We choose 'WSI_001' because, for each biopsy, we currently have only one WSI selected.\n",
    "# This naming convention is used in anticipation of potentially using multiple WSIs in the future.\n",
    "# The code iterates over each row in 'pat_df'. If the 'WSI_Selected' column is not null (indicating a selected WSI),\n",
    "# it assigns a fake name using the format 'Biopsy_{index}_WSI_001'. Otherwise, it assigns None.\n",
    "pat_df['WSI_Selected_Fake_Name'] = [\n",
    "    f\"Biopsy_{i+1:03d}_WSI_001\" if pd.notna(row['WSI_Selected']) else None\n",
    "    for i, row in pat_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pat_df[pat_df[\"WSI_Selected\"].notna()\n",
    "                & pat_df[\"ESRDorEGFR40BX_LR\"].notna()\n",
    "                & pat_df[\"DaysBXtoESRDorEGFR40_LR\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated clinical DataFrame to the specified file\n",
    "pat_df.to_csv(VESSEL_NEPTUNE_PAT_INFO_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
