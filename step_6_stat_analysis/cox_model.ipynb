{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.utils_constants import (VESSEL_NEPTUNE_PAT_INFO_W_SCORE_W_FEATURE_PATH as  VESSEL_PAT_INFO_W_SCORE_W_FEATURE_PATH,\n",
    "                                   DISEASE_TYPES, ARTERY_TYPES,\n",
    ")\n",
    "\n",
    "SEVERITY_MAPPING = {\n",
    "    '0:absent': 0,\n",
    "    '1:mild (1-25%)': 1,\n",
    "    '2:moderate (26-50%)': 2,\n",
    "    '3:severe (>50%)': 3,\n",
    "}\n",
    "\n",
    "DEMOGRAPHICS = ['PAT_Sex', 'PAT_Race', 'PAT_Hispanic', 'PAT_AgeV3']\n",
    "CLININCAL_DATA = ['PAT_Cohort', 'eGFRatBx', 'UPCRatBx']\n",
    "DESCRIPTOR = ['ArterioSclerosis', \"ArterialHyalinosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_map(x, positive_value):\n",
    "    return 1 if x == positive_value else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples before QC: 243\n",
      "PAT_Cohort\n",
      "4 - FSGS    134\n",
      "2 - MCD     109\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "suffix = \"_measurements_exclude_hya_manual\"\n",
    "agg_feature_path = VESSEL_PAT_INFO_W_SCORE_W_FEATURE_PATH.replace(\".csv\", f\"{suffix}.csv\")\n",
    "pat_df = pd.read_csv(agg_feature_path)\n",
    "\n",
    "pat_df.dropna(subset = DEMOGRAPHICS + CLININCAL_DATA, inplace=True)\n",
    "total_samples_before_qc = len(pat_df)\n",
    "print(\"Number of Samples before QC:\", total_samples_before_qc)\n",
    "print(pat_df['PAT_Cohort'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 225 with 18 excluded\n"
     ]
    }
   ],
   "source": [
    "pat_df = pat_df[pat_df[\"Num_All_Arteries\"] > 0]\n",
    "total_samples = len(pat_df)\n",
    "print(\"Number of Samples:\", total_samples, f'with {total_samples_before_qc - total_samples} excluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAT_Cohort\n",
      "4 - FSGS    127\n",
      "2 - MCD      98\n",
      "Name: count, dtype: int64\n",
      "Percentage of MCD: 98 (43.56%), FSGS: 127 (56.44%)\n",
      "PAT_Sex\n",
      "1: Male      130\n",
      "2: Female     95\n",
      "Name: count, dtype: int64\n",
      "Percentage of Males: 130 (57.78%), Females: 95 (42.22%)\n",
      "Number of samples under 18: 106, Percentage of samples under 18: 47.11%\n"
     ]
    }
   ],
   "source": [
    "# Calculating percentages for the cohort\n",
    "print(pat_df['PAT_Cohort'].value_counts())\n",
    "pat_df['PAT_Cohort'] = pat_df['PAT_Cohort'].apply(lambda x: binary_map(x, '2 - MCD'))\n",
    "mcd_count = np.sum(pat_df['PAT_Cohort'])  # Assuming 'PAT_Cohort' counts MCD occurrences directly\n",
    "fsgs_count = total_samples - mcd_count  # Assuming remaining are FSGS\n",
    "# Calculate percentages\n",
    "mcd_percent = (mcd_count / total_samples) * 100\n",
    "fsgs_percent = (fsgs_count / total_samples) * 100\n",
    "print(f\"Percentage of MCD: {mcd_count} ({mcd_percent:.2f}%), FSGS: {fsgs_count} ({fsgs_percent:.2f}%)\")\n",
    "\n",
    "print(pat_df['PAT_Sex'].value_counts())\n",
    "pat_df['PAT_Sex'] = pat_df['PAT_Sex'].apply(lambda x: binary_map(x, '2: Female'))\n",
    "male_count = total_samples - np.sum(pat_df['PAT_Sex'])\n",
    "male_percent = (male_count / total_samples) * 100\n",
    "female_count = np.sum(pat_df['PAT_Sex'])\n",
    "female_percent = (female_count / total_samples) * 100\n",
    "print(f\"Percentage of Males: {male_count} ({male_percent:.2f}%), Females: {female_count} ({female_percent:.2f}%)\")\n",
    "\n",
    "# Calculating under 18 count and percentage\n",
    "under_18_count = np.sum(pat_df['PAT_AgeV3'] < 18)\n",
    "under_18_percent = (under_18_count / total_samples) * 100\n",
    "print(f\"Number of samples under 18: {under_18_count}, Percentage of samples under 18: {under_18_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race distribution:\n",
      "White or Caucasian & 118 (52.44%)\n",
      "Black or African American & 59 (26.22%)\n",
      "Others (multiracial or unknown) & 25 (11.11%)\n",
      "Asian or Asian American & 23 (10.22%)\n",
      "PAT_Hispanic\n",
      "2: Not Hispanic or Latino    168\n",
      "1: Hispanic or Latino         53\n",
      "97: Unknown                    4\n",
      "Name: count, dtype: int64\n",
      "Percentage of Hispanic or Latino: 53 (23.56%)\n"
     ]
    }
   ],
   "source": [
    "race_mapping = {\n",
    "    '2: Asian/Asian American': 'Asian or Asian American',\n",
    "    '3: Black/African American': 'Black or African American',\n",
    "    '5: White/Caucasian': 'White or Caucasian',\n",
    "    '0: Multi-Racial': 'Others (multiracial or unknown)',\n",
    "    '97: Unknown': 'Others (multiracial or unknown)'\n",
    "}\n",
    "\n",
    "# Applying the mapping\n",
    "pat_df['Mapped_Race'] = pat_df['PAT_Race'].map(race_mapping)\n",
    "new_race_counts = pat_df['Mapped_Race'].value_counts()\n",
    "\n",
    "# Calculating percentages\n",
    "new_race_percentages = (new_race_counts / total_samples) * 100\n",
    "\n",
    "# Printing the results in LaTeX format\n",
    "print(\"Race distribution:\")\n",
    "for race, count in new_race_counts.items():\n",
    "    percentage = new_race_percentages[race]\n",
    "    print(f\"{race} & {count} ({percentage:.2f}%)\")\n",
    "pat_df['PAT_Race'] = pat_df['PAT_Race'].apply(lambda x: binary_map(x, '3: Black/African American'))\n",
    "\n",
    "\n",
    "print(pat_df['PAT_Hispanic'].value_counts())\n",
    "pat_df['PAT_Hispanic'] = pat_df['PAT_Hispanic'].apply(lambda x: binary_map(x, '1: Hispanic or Latino'))\n",
    "hispanic_count = np.sum(pat_df['PAT_Hispanic'])\n",
    "hispanic_percent = (hispanic_count / total_samples) * 100\n",
    "print(f\"Percentage of Hispanic or Latino: {hispanic_count} ({hispanic_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median eGFR: 84.76, IQR: (54.11, 105.69)\n",
      "Median UPCR: 3.20, IQR: (1.15, 8.67)\n"
     ]
    }
   ],
   "source": [
    "# Calculating medians and IQRs for eGFR and UPCR\n",
    "egfr_median = np.median(pat_df['eGFRatBx'])\n",
    "egfr_25th = np.percentile(pat_df['eGFRatBx'], 25)\n",
    "egfr_75th = np.percentile(pat_df['eGFRatBx'], 75)\n",
    "egfr_iqr = egfr_75th - egfr_25th\n",
    "\n",
    "upcr_median = np.median(pat_df['UPCRatBx'])\n",
    "upcr_25th = np.percentile(pat_df['UPCRatBx'], 25)\n",
    "upcr_75th = np.percentile(pat_df['UPCRatBx'], 75)\n",
    "upcr_iqr = upcr_75th - upcr_25th\n",
    "\n",
    "# Output results with two decimal places\n",
    "print(f\"Median eGFR: {egfr_median:.2f}, IQR: ({egfr_25th:.2f}, {egfr_75th:.2f})\")\n",
    "print(f\"Median UPCR: {upcr_median:.2f}, IQR: ({upcr_25th:.2f}, {upcr_75th:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArterioSclerosis Distribution:\n",
      "                  Count Percentage\n",
      "ArterioSclerosis                  \n",
      "0.0                 120     53.33%\n",
      "1.0                  46     20.44%\n",
      "NaN                  27     12.00%\n",
      "2.0                  19      8.44%\n",
      "3.0                  13      5.78%\n",
      "ArterialHyalinosis Distribution:\n",
      "                    Count Percentage\n",
      "ArterialHyalinosis                  \n",
      "0.0                   150     66.67%\n",
      "1.0                    40     17.78%\n",
      "NaN                    24     10.67%\n",
      "2.0                    11      4.89%\n"
     ]
    }
   ],
   "source": [
    "pat_df['ArterioSclerosis'] = pat_df['ArterioSclerosis'].map(SEVERITY_MAPPING)\n",
    "pat_df['ArterialHyalinosis'] = pat_df['ArterialHyalinosis'].map(SEVERITY_MAPPING)\n",
    "# Function to calculate count and percentage and return a formatted DataFrame\n",
    "def calculate_distribution(column):\n",
    "    value_counts = column.value_counts(dropna=False)\n",
    "    percentage = column.value_counts(normalize=True, dropna=False) * 100\n",
    "    # Formatting percentage with two decimal places\n",
    "    formatted_percentage = percentage.map(\"{:.2f}%\".format)\n",
    "    return pd.DataFrame({\n",
    "        'Count': value_counts,\n",
    "        'Percentage': formatted_percentage\n",
    "    })\n",
    "\n",
    "# Calculate for both conditions\n",
    "arterio_sclerosis_result = calculate_distribution(pat_df['ArterioSclerosis'])\n",
    "arterial_hyalinosis_result = calculate_distribution(pat_df['ArterialHyalinosis'])\n",
    "\n",
    "# Display the results\n",
    "print(\"ArterioSclerosis Distribution:\")\n",
    "print(arterio_sclerosis_result)\n",
    "print(\"ArterialHyalinosis Distribution:\")\n",
    "print(arterial_hyalinosis_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to various columns\n",
    "covariates_to_normalize = ['PAT_AgeV3', 'eGFRatBx', 'UPCRatBx', 'ArterioSclerosis', 'ArterialHyalinosis']  # add numerical columns here\n",
    "scaler = StandardScaler() # choose a scaler?\n",
    "pat_df[covariates_to_normalize] = scaler.fit_transform(pat_df[covariates_to_normalize]) # in place\n",
    "pat_df['DaysBXtoESRDorEGFR40_LR'] = pd.to_numeric(pat_df['DaysBXtoESRDorEGFR40_LR'], errors='coerce')\n",
    "pat_df['ESRDorEGFR40BX_LR'] = pat_df['ESRDorEGFR40BX_LR'].map({'1: Yes': 1, '0: No': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Count of >0  Sum of Values\n",
      "Num_Arterioles                     217         1499.0\n",
      "Num_Interlobular_Arteries          196          686.0\n",
      "Num_Arcuate_Arteries                84          131.0\n"
     ]
    }
   ],
   "source": [
    "columns_of_interest = ['Num_Arterioles', 'Num_Interlobular_Arteries', 'Num_Arcuate_Arteries']\n",
    "\n",
    "# Calculating the number of rows with values > 0 only for the specified columns\n",
    "greater_than_zero_counts = (pat_df[columns_of_interest] > 0).sum()\n",
    "\n",
    "# Calculating the sum of each specified column\n",
    "sum_values = pat_df[columns_of_interest].sum()\n",
    "\n",
    "# Combine the results into a single DataFrame for a clear presentation\n",
    "result = pd.DataFrame({\n",
    "    'Count of >0': greater_than_zero_counts,\n",
    "    'Sum of Values': sum_values\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_by_type = {'Arterioles': {'Hyalinosis Area Ratio',\n",
    "  'Intima Area Ratio',\n",
    "  'Intima Median',\n",
    "  'Log Artery Area',\n",
    "  'Lumen Area Ratio'},\n",
    " 'Interlobular Arteries': {'Intima Area Ratio', 'Ratio Average'},\n",
    " 'Arcuate Arteries': {'Intima Area Ratio', 'Ratio Median'}}\n",
    "\n",
    "agged_features_by_type = {}\n",
    "agged_scores_by_type = {}\n",
    "\n",
    "for artery_type in ARTERY_TYPES:\n",
    "    agged_features = []\n",
    "    for feature_name in selected_features_by_type[artery_type]:\n",
    "        for agg_metric in [\"Max\", \"Median\", \"75th\"]:\n",
    "            agged_feature = '_'.join([agg_metric, feature_name, \"in\", artery_type])\n",
    "            agged_features.append(agged_feature.replace(\" \", \"_\"))\n",
    "    agged_features_by_type[artery_type] = agged_features\n",
    "\n",
    "    score_features = []\n",
    "    for disease in DISEASE_TYPES:\n",
    "        if artery_type == \"Arcuate Arteries\" and disease == \"Hyalinosis\": continue\n",
    "        for agg_metric in [\"Max\", \"Median\", \"75th\"]:\n",
    "            score_feature= '_'.join([agg_metric, disease, \"Severity\", \"in\", artery_type])\n",
    "            score_features.append(score_feature.replace(\" \", \"_\"))\n",
    "    agged_scores_by_type[artery_type] = score_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artery_type in ARTERY_TYPES:\n",
    "    scaler = StandardScaler()\n",
    "    agg_features = agged_features_by_type[artery_type]\n",
    "    score_features = agged_scores_by_type[artery_type]\n",
    "    pat_df[agg_features + score_features] = scaler.fit_transform(pat_df[agg_features + score_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_model_analysis(df, base, features):\n",
    "    # Create a figure and axis object with proper dimensions\n",
    "    # Initialize and fit the Cox proportional hazards model\n",
    "    if len(features) > 0:\n",
    "        cph = CoxPHFitter(penalizer=0.01, l1_ratio=1)\n",
    "        cph.fit(df, duration_col='DaysBXtoESRDorEGFR40_LR', event_col='ESRDorEGFR40BX_LR', formula=\"+\".join(features))\n",
    "        summary = cph.summary\n",
    "        # Compute the absolute values of the coefficients and sort them\n",
    "        summary['abs_coef'] = summary['coef'].abs()\n",
    "        summary_sorted = summary.sort_values(by='abs_coef', ascending=False)\n",
    "        selected_features = summary_sorted[summary_sorted[\"abs_coef\"] > 0.1].index.values.tolist()\n",
    "    else:\n",
    "        selected_features = features\n",
    "\n",
    "    cph = CoxPHFitter(penalizer=0.01, l1_ratio=1)\n",
    "    cph.fit(df, duration_col='DaysBXtoESRDorEGFR40_LR', event_col='ESRDorEGFR40BX_LR', formula=\"+\".join(base + selected_features))\n",
    "    print(f\"Cox Model Concordance: {cph.concordance_index_:.2f}\")\n",
    "    return cph, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cox_stat_univariate(df, base, feature):\n",
    "    cph = CoxPHFitter(penalizer=0.01, l1_ratio=1)\n",
    "    cph.fit(df, duration_col='DaysBXtoESRDorEGFR40_LR', event_col='ESRDorEGFR40BX_LR', formula=\"+\".join(base + [feature]))\n",
    "    row = cph.summary.loc[feature, [\"exp(coef)\", \"exp(coef) lower 95%\", \"exp(coef) upper 95%\", \"p\"]]\n",
    "    hr, p = row[\"exp(coef)\"], row[\"p\"]\n",
    "    lower_95, upper_95 = row[\"exp(coef) lower 95%\"], row[\"exp(coef) upper 95%\"]\n",
    "    if len(base) == 0:\n",
    "        print(f\"Unadjusted {feature}: HR {hr:.2f} ({lower_95:.2f}-{upper_95:.2f}), p: {p:.3f}\")\n",
    "    else:\n",
    "        print(f\"adjusted {feature}: HR {hr:.2f} ({lower_95:.2f}-{upper_95:.2f}), p: {p:.3f}\")\n",
    "\n",
    "def cox_single_analysis(pat_df_selected, selected_features):\n",
    "    for feature in selected_features:\n",
    "        get_cox_stat_univariate(pat_df_selected, [], feature)\n",
    "        get_cox_stat_univariate(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 147)\n",
      "Cox Model Concordance: 0.69\n",
      "Cox Model Concordance: 0.72\n",
      "Cox Model Concordance: 0.75\n",
      "Unadjusted Median_Arteriosclerosis_Severity_in_Arcuate_Arteries: HR 0.82 (0.52-1.31), p: 0.409\n",
      "adjusted Median_Arteriosclerosis_Severity_in_Arcuate_Arteries: HR 0.68 (0.34-1.39), p: 0.291\n",
      "Unadjusted Max_Arteriosclerosis_Severity_in_Arcuate_Arteries: HR 0.95 (0.59-1.53), p: 0.828\n",
      "adjusted Max_Arteriosclerosis_Severity_in_Arcuate_Arteries: HR 0.87 (0.48-1.57), p: 0.645\n",
      "Cox Model Concordance: 0.74\n",
      "Unadjusted 75th_Intima_Area_Ratio_in_Arcuate_Arteries: HR 0.69 (0.41-1.16), p: 0.163\n",
      "adjusted 75th_Intima_Area_Ratio_in_Arcuate_Arteries: HR 0.54 (0.27-1.09), p: 0.084\n",
      "Unadjusted Median_Ratio_Median_in_Arcuate_Arteries: HR 0.71 (0.43-1.17), p: 0.174\n",
      "adjusted Median_Ratio_Median_in_Arcuate_Arteries: HR 0.57 (0.29-1.12), p: 0.103\n"
     ]
    }
   ],
   "source": [
    "agged_features = agged_features_by_type[\"Arcuate Arteries\"]\n",
    "score_features = agged_scores_by_type[\"Arcuate Arteries\"]\n",
    "pat_df_selected = pat_df.dropna(subset = DEMOGRAPHICS + CLININCAL_DATA  + DESCRIPTOR + \n",
    "                                score_features + agged_features, inplace = False)\n",
    "print(pat_df_selected.shape)\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , [])\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , DESCRIPTOR)\n",
    "cph, selected_score_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , score_features)\n",
    "cox_single_analysis(pat_df_selected, selected_score_features)\n",
    "\n",
    "cph, selected_agged_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , agged_features)\n",
    "cox_single_analysis(pat_df_selected, selected_agged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 147)\n",
      "Cox Model Concordance: 0.70\n",
      "Cox Model Concordance: 0.72\n",
      "Cox Model Concordance: 0.71\n",
      "Unadjusted Median_Arteriosclerosis_Severity_in_Interlobular_Arteries: HR 0.97 (0.72-1.32), p: 0.861\n",
      "adjusted Median_Arteriosclerosis_Severity_in_Interlobular_Arteries: HR 0.88 (0.63-1.25), p: 0.487\n",
      "Unadjusted Max_Arteriosclerosis_Severity_in_Interlobular_Arteries: HR 1.07 (0.81-1.42), p: 0.629\n",
      "adjusted Max_Arteriosclerosis_Severity_in_Interlobular_Arteries: HR 1.02 (0.73-1.41), p: 0.928\n",
      "Cox Model Concordance: 0.72\n",
      "Unadjusted 75th_Ratio_Average_in_Interlobular_Arteries: HR 0.95 (0.70-1.30), p: 0.742\n",
      "adjusted 75th_Ratio_Average_in_Interlobular_Arteries: HR 0.92 (0.65-1.29), p: 0.617\n",
      "Unadjusted Max_Intima_Area_Ratio_in_Interlobular_Arteries: HR 1.08 (0.81-1.44), p: 0.579\n",
      "adjusted Max_Intima_Area_Ratio_in_Interlobular_Arteries: HR 1.04 (0.73-1.46), p: 0.841\n",
      "Unadjusted Median_Intima_Area_Ratio_in_Interlobular_Arteries: HR 1.00 (0.74-1.37), p: 0.975\n",
      "adjusted Median_Intima_Area_Ratio_in_Interlobular_Arteries: HR 1.00 (1.00-1.00), p: 0.999\n",
      "Unadjusted Median_Ratio_Average_in_Interlobular_Arteries: HR 0.95 (0.69-1.29), p: 0.725\n",
      "adjusted Median_Ratio_Average_in_Interlobular_Arteries: HR 0.91 (0.65-1.28), p: 0.589\n"
     ]
    }
   ],
   "source": [
    "agged_features = agged_features_by_type[\"Interlobular Arteries\"]\n",
    "score_features = agged_scores_by_type[\"Interlobular Arteries\"]\n",
    "\n",
    "pat_df_selected = pat_df.dropna(subset = DEMOGRAPHICS + CLININCAL_DATA + DESCRIPTOR + \n",
    "                                score_features + agged_features, inplace = False)\n",
    "print(pat_df_selected.shape)\n",
    "\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , [])\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , DESCRIPTOR)\n",
    "cph, selected_score_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , score_features)\n",
    "cox_single_analysis(pat_df_selected, selected_score_features)\n",
    "\n",
    "cph, selected_agged_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , agged_features)\n",
    "cox_single_analysis(pat_df_selected, selected_agged_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 147)\n",
      "Cox Model Concordance: 0.70\n",
      "Cox Model Concordance: 0.70\n",
      "Cox Model Concordance: 0.73\n",
      "Unadjusted 75th_Hyalinosis_Severity_in_Arterioles: HR 1.06 (0.80-1.40), p: 0.693\n",
      "adjusted 75th_Hyalinosis_Severity_in_Arterioles: HR 1.01 (0.74-1.38), p: 0.949\n",
      "Unadjusted Median_Hyalinosis_Severity_in_Arterioles: HR 1.26 (1.01-1.57), p: 0.043\n",
      "adjusted Median_Hyalinosis_Severity_in_Arterioles: HR 1.26 (0.99-1.60), p: 0.057\n",
      "Unadjusted Max_Hyalinosis_Severity_in_Arterioles: HR 1.24 (0.92-1.66), p: 0.154\n",
      "adjusted Max_Hyalinosis_Severity_in_Arterioles: HR 1.23 (0.87-1.73), p: 0.238\n",
      "Unadjusted Max_Arteriosclerosis_Severity_in_Arterioles: HR 1.32 (1.05-1.65), p: 0.016\n",
      "adjusted Max_Arteriosclerosis_Severity_in_Arterioles: HR 1.32 (1.04-1.67), p: 0.023\n",
      "Cox Model Concordance: 0.75\n",
      "Unadjusted 75th_Log_Artery_Area_in_Arterioles: HR 1.00 (0.99-1.01), p: 0.999\n",
      "adjusted 75th_Log_Artery_Area_in_Arterioles: HR 1.00 (1.00-1.00), p: 0.999\n",
      "Unadjusted 75th_Lumen_Area_Ratio_in_Arterioles: HR 0.73 (0.53-1.01), p: 0.057\n",
      "adjusted 75th_Lumen_Area_Ratio_in_Arterioles: HR 0.69 (0.48-0.98), p: 0.037\n",
      "Unadjusted 75th_Intima_Median_in_Arterioles: HR 1.31 (0.99-1.74), p: 0.063\n",
      "adjusted 75th_Intima_Median_in_Arterioles: HR 1.30 (0.96-1.78), p: 0.093\n",
      "Unadjusted Median_Intima_Median_in_Arterioles: HR 1.11 (0.81-1.53), p: 0.519\n",
      "adjusted Median_Intima_Median_in_Arterioles: HR 1.09 (0.77-1.55), p: 0.631\n",
      "Unadjusted Max_Log_Artery_Area_in_Arterioles: HR 1.14 (0.83-1.55), p: 0.416\n",
      "adjusted Max_Log_Artery_Area_in_Arterioles: HR 1.15 (0.82-1.60), p: 0.419\n",
      "Unadjusted Median_Log_Artery_Area_in_Arterioles: HR 1.04 (0.77-1.40), p: 0.804\n",
      "adjusted Median_Log_Artery_Area_in_Arterioles: HR 1.02 (0.74-1.41), p: 0.908\n",
      "Unadjusted Max_Hyalinosis_Area_Ratio_in_Arterioles: HR 1.24 (0.99-1.55), p: 0.061\n",
      "adjusted Max_Hyalinosis_Area_Ratio_in_Arterioles: HR 1.28 (1.00-1.62), p: 0.046\n"
     ]
    }
   ],
   "source": [
    "agged_features = agged_features_by_type[\"Arterioles\"]\n",
    "score_features = agged_scores_by_type[\"Arterioles\"]\n",
    "pat_df_selected = pat_df.dropna(subset = DEMOGRAPHICS + CLININCAL_DATA + DESCRIPTOR + \n",
    "                                score_features + agged_features, inplace = False)\n",
    "print(pat_df_selected.shape)\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , [])\n",
    "cph, _ = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , DESCRIPTOR)\n",
    "cph, selected_score_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , score_features)\n",
    "cox_single_analysis(pat_df_selected, selected_score_features)\n",
    "\n",
    "cph, selected_agged_features = cox_model_analysis(pat_df_selected, DEMOGRAPHICS + CLININCAL_DATA , agged_features)\n",
    "cox_single_analysis(pat_df_selected, selected_agged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
