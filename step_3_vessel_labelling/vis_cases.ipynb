{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import cv2 \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import json\n",
    "import openslide\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from util import plot_artery_counts_by_case, barplot, distribution_analysis\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.utils_data import get_veesel_sheets, get_segmentations\n",
    "from utils.utils_geometry import get_contours_by_classification, is_contour_match_bounds, offset_contours\n",
    "\n",
    "from utils.utils_survival import survival_analysis\n",
    "from utils.utils_vis import gallery_view\n",
    "from utils.utils_constants import (ARTERY_TYPES,\n",
    "                                   DISEASE_TYPES,\n",
    "                                   VESSEL_NEPTUNE_PAT_INFO_W_SCORE_PATH as VESSEL_PAT_INFO_W_SCORE_PATH,\n",
    "                                   CLASSIFICATION_PATH,\n",
    "                                   TISSUE_SEGMENTATION_REGION_PATH,\n",
    "                                   SEGMENTATION_DIR,\n",
    "                                   COMBINED_CLASSIFICATION_PATH,\n",
    "                                   ANALYSIS_DOC_PATH,\n",
    "                                   TRI_CASE_DIR,\n",
    "                                   CROPPED_VESSELS_DIR)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.read_csv(VESSEL_PAT_INFO_W_SCORE_PATH)\n",
    "# pat_df['DaysBXtoESRDorEGFR40_LR'] = pd.to_numeric(pat_df['DaysBXtoESRDorEGFR40_LR'], errors='coerce')\n",
    "pat_df['ESRDorEGFR40BX_LR'] = pat_df['ESRDorEGFR40BX_LR'].map({'1: Yes': 1, '0: No': 0}).astype(int)\n",
    "pat_df = pat_df[pat_df[\"Num_All_Arteries\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contour_intersecting_or_within(cnt_iner, cnt_outer):\n",
    "    \"\"\"Determine if an inner contour intersects or is completely within an outer contour.\"\"\"\n",
    "    return any(cv2.pointPolygonTest(cnt_outer, (int(point[0]), int(point[1])), False) >= 0 for point in cnt_iner)\n",
    "\n",
    "\n",
    "def check_bbox_with_contour(bbox_x, bbox_y, bbox_width, bbox_height, cortex_contour):\n",
    "    # Convert bounding box to contour\n",
    "    rect_contour = np.array([\n",
    "        [bbox_x, bbox_y],\n",
    "        [bbox_x + bbox_width, bbox_y],\n",
    "        [bbox_x + bbox_width, bbox_y + bbox_height],\n",
    "        [bbox_x, bbox_y + bbox_height]\n",
    "    ], dtype=np.int32).reshape((-1, 2))\n",
    "\n",
    "    return is_contour_intersecting_or_within(rect_contour, cortex_contour)\n",
    "\n",
    "def vis_slide(classifications, segmentations, cortex_contour=None):\n",
    "    for artery_type in ARTERY_TYPES:\n",
    "        print(artery_type)\n",
    "        images = []\n",
    "        titles = []\n",
    "        for index, row in classifications[classifications[\"Artery Type\"] == artery_type].iterrows():\n",
    "            bbox_x, bbox_y, bbox_width, bbox_height = map(int, row[\"Bounding Box\"].split(\",\"))\n",
    "\n",
    "            if cortex_contour is not None:\n",
    "                is_inside = check_bbox_with_contour(bbox_x, bbox_y, bbox_width, bbox_height, cortex_contour)\n",
    "                if not is_inside:\n",
    "                    continue\n",
    "            outer_contours = get_contours_by_classification(\n",
    "                segmentations,\n",
    "                lambda contour: is_contour_match_bounds(\n",
    "                    contour, (bbox_x, bbox_y, bbox_width, bbox_height)\n",
    "                ),\n",
    "                \"Media\"\n",
    "            )\n",
    "            assert(len(outer_contours)) == 1\n",
    "            # vessel_size = int(np.log(cv2.contourArea(outer_contours[0])))\n",
    "            area = cv2.contourArea(outer_contours[0])\n",
    "            vessel_size = f\"{round(area):.1e}\"\n",
    "\n",
    "            # cv2.drawContours(slide, outer_contours, -1, [255, 0, 0], 2)  # Outer contour in red\n",
    "            # Construct the path to the image file\n",
    "            image_path = os.path.join(CROPPED_VESSELS_DIR, artery_type, \n",
    "                                    row[\"Image Name\"].replace(\".png\", \"_w_ann.png\"))\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Correct function to load the image\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n",
    "            images.append(img)\n",
    "            # Create a title using multiple fields from the DataFrame\n",
    "            title = f\"Size: {vessel_size}; AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "            # title = f\"B{row['Image Name'].split('_')[1]}{row['Artery ID']}-AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "            titles.append(title)\n",
    "        if len(images) > 0:\n",
    "            gallery_view(images, titles, cols=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_border_of_cnt(cnt, border=0):\n",
    "    # cnt: coordinates, list of list, [[0, 0], [0, 1], ...]\n",
    "    cnt = np.array(cnt, dtype=int).squeeze()\n",
    "    xmin, xmax = np.min(cnt[:, 0]), np.max(cnt[:, 0])\n",
    "    ymin, ymax = np.min(cnt[:, 1]), np.max(cnt[:, 1])\n",
    "    return (xmin-border, xmax+border, ymin-border, ymax+border)\n",
    "\n",
    "def get_border_of_ann(ann, border=50):\n",
    "    # ann: need to be cleaned to get coordinates\n",
    "    (xmin, xmax) = (float('inf'), 0)\n",
    "    (ymin, ymax) = (float('inf'), 0)\n",
    "    for (i, ann_i) in enumerate(ann):\n",
    "#         coords_raw = ann_i['geometry']['coordinates']\n",
    "        coords = ann_i['geometry']['coordinates']\n",
    "        curr_xmin, curr_xmax, curr_ymin, curr_ymax = get_border_of_cnt(coords)\n",
    "        xmin = min(xmin, curr_xmin)\n",
    "        xmax = max(xmax, curr_xmax)\n",
    "        ymin = min(ymin, curr_ymin)\n",
    "        ymax = max(ymax, curr_ymax)\n",
    "\n",
    "    return (xmin-border, xmax+border, ymin-border, ymax+border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_df_selected = pat_df[pat_df['ESRDorEGFR40BX_LR'] == 1].nsmallest(40, 'DaysBXtoESRDorEGFR40_LR')\n",
    "\n",
    "with open(TISSUE_SEGMENTATION_REGION_PATH, 'r') as file:\n",
    "     tissue_segmentations = json.load(file)\n",
    "\n",
    "available_sheetnames = pd.ExcelFile(CLASSIFICATION_PATH).sheet_names\n",
    "\n",
    "count = 0\n",
    "for i, (index, row) in enumerate(pat_df.iterrows()):\n",
    "     if i!=1: continue\n",
    "     slide_filename = row[\"WSI_Selected\"]\n",
    "     logging.info(f\"Processing: {i+1}/{len(pat_df)}: {slide_filename}\")\n",
    "\n",
    "     slide_path = os.path.join(TRI_CASE_DIR, slide_filename)\n",
    "     slide_0 = openslide.OpenSlide(slide_path)\n",
    "\n",
    "     slide_basename = os.path.splitext(slide_filename)[0]\n",
    "     classifications = get_veesel_sheets(CLASSIFICATION_PATH, slide_basename, available_sheetnames, remove_others=True)\n",
    "     if len(classifications) > 25: continue\n",
    "     if len(classifications) < 10: continue\n",
    "     if len(np.unique(classifications[\"Artery Type\"].values)) < 3: continue\n",
    "     if len(classifications[classifications[\"Artery Type\"] == \"Arcuate Arteries\"]) < 2: continue\n",
    "     count += 1\n",
    "     if count >= 5: break\n",
    "     segmentations_path = os.path.join(SEGMENTATION_DIR, f\"{slide_basename}.geojson\")\n",
    "     segmentations = get_segmentations(segmentations_path, clean=True)\n",
    "\n",
    "     # xmin, xmax, ymin, ymax = get_border_of_ann(segmentations, border=0)\n",
    "     # slide = slide_0.read_region((xmin, ymin), 0, (xmax-xmin, ymax-ymin))\n",
    "     \n",
    "     # level = min(4, len(slide_0.level_dimensions)-1)\n",
    "     # downsample = slide_0.level_downsamples[level] \n",
    "\n",
    "     # # Adjust coordinates for the target level\n",
    "     # xmin_adj = int(xmin / downsample)\n",
    "     # xmax_adj = int(xmax / downsample)\n",
    "     # ymin_adj = int(ymin / downsample)\n",
    "     # ymax_adj = int(ymax / downsample)\n",
    "     # width = xmax_adj - xmin_adj\n",
    "     # height = ymax_adj - ymin_adj\n",
    "\n",
    "     # Read the region from the specified level\n",
    "     # slide = slide_0.read_region((xmin_adj, ymin_adj), level, (width, height))\n",
    "     # slide = np.asarray(slide)\n",
    "     # slide = cv2.cvtColor(slide, cv2.COLOR_RGBA2RGB)\n",
    "     # cortex_contours = get_contours_by_classification(segmentations, filter_fn=lambda x: True, classification=\"Cortex\")\n",
    "     # cortex_contours = offset_contours(cortex_contours, (xmin, ymin))\n",
    "     # # cortex_contours = [np.round(cnt / downsample).astype(np.int32).reshape(-1, 1, 2) for cnt in cortex_contours]\n",
    "     # if len(cortex_contours) > 0:\n",
    "     #      cv2.drawContours(slide, cortex_contours, -1, [255, 0, 0], 2)  # Outer contour in red\n",
    "     \n",
    "     # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "     # cax = ax.imshow(slide)\n",
    "     # plt.axis(\"off\")\n",
    "     # plt.show()\n",
    "     \n",
    "     vis_slide(classifications, segmentations, cortex_contour=None)\n",
    "\n",
    "\n",
    "     # if len(cortex_contours) == 0:\n",
    "     #      continue\n",
    "     \n",
    "     # for cortex_contour in cortex_contours:\n",
    "     #      x, y, w, h = cv2.boundingRect(cortex_contour)  \n",
    "          \n",
    "     #      slide = slide_0.read_region((x, y), 0, (w, h))\n",
    "     #      slide = np.asarray(slide)\n",
    "     #      slide = cv2.cvtColor(slide, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "     #      slide = vis_slide(slide, slide_filename, classifications, segmentations, cortex_contour=cortex_contour)\n",
    "     #      fig, ax = plt.subplots()\n",
    "     #      cax = ax.imshow(slide)\n",
    "     #      plt.axis(\"off\")\n",
    "     #      plt.show()\n",
    "\n",
    "    # slide_basename = os.path.splitext(slide_filename)[0]\n",
    "    # classifications = get_veesel_sheets(CLASSIFICATION_PATH, slide_basename, available_sheetnames, remove_others=True)\n",
    "    # if classifications.empty:\n",
    "    #     continue  # Skip to if no relevant data\n",
    "    # vis_slide(slide_filename, classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
