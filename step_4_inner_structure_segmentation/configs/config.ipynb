{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./config_hyalinosis.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from utils.utils_constants import (COMBINED_CLASSIFICATION_PATH, \n",
    "                                   CROPPED_VESSELS_COMBINED_DIR, \n",
    "                                   CLASSIFICATION_SEVERITY_MAPPING)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CONFIG_PATH = f\"./config_hyalinosis.json\"\n",
    "CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"task\": \"hyalinosis\",\n",
    "    \n",
    "    \"net\": {\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 2,\n",
    "        \"padding\": True,  # Ensure boolean values are capitalized in Python\n",
    "        \"depth\": 5,\n",
    "        \"wf\": 4,\n",
    "        \"up_mode\": \"upconv\",\n",
    "        \"batch_norm\": True,  # Ensure boolean values are capitalized in Python\n",
    "    },\n",
    "\n",
    "    \"training\": {\n",
    "        \"gpu_id\": 0,\n",
    "        \"batch_size\": 10,\n",
    "        \"num_epochs\": 50,\n",
    "        \"lr\": 0.001,\n",
    "        \"edge_weight\": 1.2,\n",
    "        \"class_weights\": [0.47, 0.53],  # Python lists should be formatted correctly\n",
    "        \"ignore_index\": -100\n",
    "    },\n",
    "\n",
    "    \"data\": {\n",
    "        \"base_path\": \"/DataMount/NEPTUNE/Cropped_Vessels_Combined/\",\n",
    "        \"mask_suffix\": \"_mask.png\",\n",
    "        \"resize_to\": 256,  # Corrected to include a trailing comma if expecting further entries\n",
    "        \"train_files\": [],\n",
    "        \"val_files\": []\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"gpu_id\": 1,\n",
    "        \"model_path\": \"models/hyalinosis_model_20240706-234141_epoch_50.pth\",\n",
    "        \"save_dir\": \"/DataMount/NEPTUNE/Cropped_Vessels_Combined_Test_Hyalinosis/\",\n",
    "        \"pred_suffix\": \"_pred_hya_20240706-234141_epoch_50.png\",\n",
    "        \"batch_size\": 1,\n",
    "        \"inference_files\": [],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_classifications = pd.read_csv(COMBINED_CLASSIFICATION_PATH)\n",
    "# # combined_classifications = combined_classifications[combined_classifications[\"Artery Type\"] != \"Others\"]\n",
    "# combined_classifications = combined_classifications[combined_classifications[\"Artery Type\"] == \"Arterioles\"]\n",
    "\n",
    "# # Generate 'Biopsy ID' by extracting relevant part from 'Image Name'\n",
    "# combined_classifications[\"Biopsy ID\"] = combined_classifications[\"Image Name\"].apply(lambda x: \"Biopsy_\" + x.split(\"_\")[1])\n",
    "\n",
    "# # Ensure that there is no data leakage between training and validation sets by consistent split\n",
    "# biopsy_ids = combined_classifications[\"Biopsy ID\"].unique()\n",
    "# # np.random.shuffle(biopsy_ids)  # Randomize the order to avoid biased splits\n",
    "\n",
    "# # Assign the first 180 unique Biopsy IDs to training and the rest to validation\n",
    "# train_biopsy_ids = biopsy_ids[:180]\n",
    "# val_biopsy_ids = biopsy_ids[180:]\n",
    "\n",
    "# # Select records for training and validation datasets based on 'Biopsy ID'\n",
    "# train_files = combined_classifications[combined_classifications[\"Biopsy ID\"].isin(train_biopsy_ids)][\"Image Name\"].values\n",
    "# val_files = combined_classifications[combined_classifications[\"Biopsy ID\"].isin(val_biopsy_ids)][\"Image Name\"].values\n",
    "\n",
    "# # Update configurations with the lists of training and validation files\n",
    "# configs[\"data\"][\"train_files\"] = [os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\")) for x in train_files]  # Convert NumPy array to list for JSON compatibility if needed\n",
    "# configs[\"data\"][\"val_files\"] = [os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\")) for x in val_files]  # Convert NumPy array to list for JSON compatibility if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_classifications = pd.read_csv(COMBINED_CLASSIFICATION_PATH)\n",
    "combined_classifications[\"Hyalinosis Severity\"] = combined_classifications[\"Hyalinosis Severity\"].map(CLASSIFICATION_SEVERITY_MAPPING)\n",
    "\n",
    "# combined_classifications = combined_classifications[combined_classifications[\"Artery Type\"] != \"Others\"]\n",
    "combined_classifications = combined_classifications[combined_classifications[\"Artery Type\"] == \"Arterioles\"]\n",
    "\n",
    "hyalinosis_color = (128, 0, 128)\n",
    "pos_img_names = []\n",
    "fake_pos_img_names = []\n",
    "for img_name in combined_classifications[combined_classifications[\"Hyalinosis Severity\"] > 0][\"Image Name\"]:\n",
    "    mask_path = os.path.join(CROPPED_VESSELS_COMBINED_DIR, img_name.replace(\".png\", \"_mask.png\"))\n",
    "    mask = cv2.cvtColor(cv2.imread(mask_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)  # Ensure the mask is read in color mode\n",
    "    if np.any(np.all(mask == hyalinosis_color, axis=-1)):\n",
    "        pos_img_names.append(img_name)\n",
    "    else:\n",
    "        fake_pos_img_names.append(img_name)\n",
    "\n",
    "neg_img_names = []\n",
    "fake_neg_img_names = []\n",
    "for img_name in combined_classifications[combined_classifications[\"Hyalinosis Severity\"] == 0][\"Image Name\"]:\n",
    "    mask_path = os.path.join(CROPPED_VESSELS_COMBINED_DIR, img_name.replace(\".png\", \"_mask.png\"))\n",
    "    mask = cv2.cvtColor(cv2.imread(mask_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)  # Ensure the mask is read in color mode\n",
    "    if not np.any(np.all(mask == hyalinosis_color, axis=-1)):\n",
    "        neg_img_names.append(img_name)\n",
    "    else:\n",
    "        fake_neg_img_names.append(img_name)\n",
    "\n",
    "# Ensure that there is no data leakage between training and validation sets by consistent split\n",
    "# filtered_classifications = combined_classifications[combined_classifications[\"Image Name\"].isin(pos_img_names+neg_img_names)]\n",
    "\n",
    "# Select records for training and validation datasets based on 'Biopsy ID'\n",
    "import random\n",
    "\n",
    "random.seed(42)  # You can choose any number you like for the seed\n",
    "train_files = pos_img_names + random.sample(neg_img_names, 100)\n",
    "val_files = fake_pos_img_names + fake_neg_img_names\n",
    "# Update configurations with the lists of training and validation files\n",
    "configs[\"data\"][\"train_files\"] = [os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\")) for x in train_files]  # Convert NumPy array to list for JSON compatibility if needed\n",
    "configs[\"data\"][\"val_files\"] = [os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\")) for x in val_files]  # Convert NumPy array to list for JSON compatibility if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for x in train_files + val_files:\n",
    "    img_path = os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\"))\n",
    "    mask_path = os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_mask.png\"))\n",
    "    img_path_dst = img_path.replace(CROPPED_VESSELS_COMBINED_DIR, CROPPED_VESSELS_COMBINED_DIR+\"_Test\")\n",
    "    mask_path_dst = mask_path.replace(CROPPED_VESSELS_COMBINED_DIR, CROPPED_VESSELS_COMBINED_DIR+\"_Test\")\n",
    "    # Copy files\n",
    "    shutil.copy(img_path, img_path_dst)\n",
    "    shutil.copy(mask_path, mask_path_dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"inference\"][\"inference_files\"] = [os.path.join(CROPPED_VESSELS_COMBINED_DIR, x.replace(\".png\", \"_ori.png\")) \n",
    "                                           for x in combined_classifications[\"Image Name\"].values]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH, 'w') as config_file:\n",
    "    json.dump(configs, config_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
