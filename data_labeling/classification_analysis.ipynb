{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import cv2 # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.utils_data import get_classifications\n",
    "from utils.utils_survival import survival_analysis\n",
    "from utils.utils_vis import save_fig\n",
    "from utils.utils_constants import (ARTERY_TYPES,\n",
    "                                   DISEASE_TYPES,\n",
    "                                   CLASSIFICATION_SEVERITY_MAPPING, \n",
    "                                   VESSEL_NEPTUNE_PAT_INFO_PATH as VESSEL_PAT_INFO_PATH, \n",
    "                                   VESSEL_NEPTUNE_PAT_INFO_W_SCORE_PATH as VESSEL_PAT_INFO_W_SCORE_PATH,\n",
    "                                   CLASSIFICATION_PATH, \n",
    "                                   COMBINED_CLASSIFICATION_PATH,\n",
    "                                   ANALYSIS_DOC_PATH,\n",
    "                                   CROPPED_VESSELS_DIR)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.read_csv(VESSEL_PAT_INFO_PATH)\n",
    "\n",
    "combined_classifications = pd.read_csv(COMBINED_CLASSIFICATION_PATH)\n",
    "combined_classifications = combined_classifications[combined_classifications[\"Artery Type\"] != \"Others\"]\n",
    "combined_classifications['Artery Type'] = pd.Categorical(combined_classifications['Artery Type'], categories=ARTERY_TYPES)\n",
    "\n",
    "for col in ['Arteriosclerosis Severity', 'Hyalinosis Severity']:\n",
    "    combined_classifications[col] = combined_classifications[col].map(CLASSIFICATION_SEVERITY_MAPPING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 18:23:32,108 - INFO - Sheet 12_26609_001_011 LUNK5 TRI not found in the classifications file.\n",
      "2024-06-25 18:23:32,569 - INFO - Sheet 12_26609_001_502 LUNK TRI not found in the classifications file.\n",
      "2024-06-25 18:23:34,405 - INFO - Sheet 13_26609_007_001 L10 TRI not found in the classifications file.\n",
      "2024-06-25 18:23:34,407 - INFO - Sheet 0_957_A_0052826 not found in the classifications file.\n",
      "2024-06-25 18:23:38,149 - INFO - Sheet 0_2878_A_0048364 not found in the classifications file.\n",
      "2024-06-25 18:23:43,313 - INFO - Sheet 13_26609_022_023 L02 TRI not found in the classifications file.\n",
      "2024-06-25 18:23:43,316 - INFO - Sheet 13_26609_022_024 L02 TRI not found in the classifications file.\n",
      "2024-06-25 18:23:53,066 - INFO - Sheet 11_26609_025_503 L UNK TRI not found in the classifications file.\n",
      "2024-06-25 18:23:54,390 - INFO - Sheet 13_26609_025_514 LUNK TRI not found in the classifications file.\n",
      "2024-06-25 18:24:01,510 - INFO - Sheet 11_26609_027_509_L3_TRI not found in the classifications file.\n",
      "2024-06-25 18:24:04,161 - INFO - Sheet 11_26609_028_005 L10 TRI not found in the classifications file.\n",
      "2024-06-25 18:24:07,747 - INFO - Sheet 0_1681_A_0056256 not found in the classifications file.\n",
      "2024-06-25 18:24:19,709 - INFO - Sheet 0_2948_A_0049536 not found in the classifications file.\n",
      "2024-06-25 18:24:21,615 - INFO - Sheet 17_26609_040_046 Control TRI not found in the classifications file.\n",
      "2024-06-25 18:24:22,486 - INFO - Sheet 13_26609_095_502 L04 TRI not found in the classifications file.\n"
     ]
    }
   ],
   "source": [
    "available_sheetnames = pd.ExcelFile(CLASSIFICATION_PATH).sheet_names\n",
    "\n",
    "artery_counts_by_case = {artery_type: [] for artery_type in ['All Arteries'] + ARTERY_TYPES}\n",
    "\n",
    "for i, (index, row) in enumerate(pat_df.iterrows()):\n",
    "    slide_filename = row[\"WSI_Selected\"]\n",
    "    slide_basename = os.path.splitext(slide_filename)[0]\n",
    "\n",
    "    classifications = get_classifications(CLASSIFICATION_PATH, slide_basename, available_sheetnames)\n",
    "\n",
    "    if classifications.empty:\n",
    "        continue  # Skip to if no relevant data\n",
    "    classifications['Artery Type'] = pd.Categorical(classifications['Artery Type'], categories=ARTERY_TYPES)\n",
    "\n",
    "    for col in ['Arteriosclerosis Severity', 'Hyalinosis Severity']:\n",
    "        classifications[col] = classifications[col].map(CLASSIFICATION_SEVERITY_MAPPING)\n",
    "\n",
    "    for col in ['Arteriosclerosis Severity', 'Hyalinosis Severity']:\n",
    "        severity_by_type = {}\n",
    "        for artery_type in ARTERY_TYPES:\n",
    "            severity_series = classifications[classifications['Artery Type'] == artery_type][col]\n",
    "            if not severity_series.empty:\n",
    "                # Calculating various statistics\n",
    "                max_severity = severity_series.max()\n",
    "                mean_severity = severity_series.mean()\n",
    "                median_severity = severity_series.median()\n",
    "                percentile_75th = severity_series.quantile(0.75)\n",
    "                non_zero_percentage = (severity_series > 0).sum() / len(severity_series)  # Percentage of non-zero severities\n",
    "            else:\n",
    "                max_severity = mean_severity = median_severity = percentile_75th = non_zero_percentage = -1  # or another indicator for no data\n",
    "\n",
    "            # Storing these values in the DataFrame\n",
    "            pat_df.loc[index, f'Max_{col}_in_{artery_type}'.replace(\" \", \"_\")] = max_severity\n",
    "            pat_df.loc[index, f'Mean_{col}_in_{artery_type}'.replace(\" \", \"_\")] = mean_severity\n",
    "            pat_df.loc[index, f'Median_{col}_in_{artery_type}'.replace(\" \", \"_\")] = median_severity\n",
    "            pat_df.loc[index, f'75th_{col}_in_{artery_type}'.replace(\" \", \"_\")] = percentile_75th\n",
    "            pat_df.loc[index, f'NonZeroPct_{col}_in_{artery_type}'.replace(\" \", \"_\")] = non_zero_percentage\n",
    "\n",
    "    artery_counts_by_case['All Arteries'].append(len(classifications))\n",
    "    for artery_type in ARTERY_TYPES:\n",
    "        count = (classifications['Artery Type'] == artery_type).sum()\n",
    "        artery_counts_by_case[artery_type].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df.to_csv(VESSEL_PAT_INFO_W_SCORE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docx.text.paragraph.Paragraph at 0x798c1aac0040>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Word document\n",
    "doc = Document()\n",
    "doc.add_heading('Artery Classification Report', level=0)\n",
    "doc.add_page_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_artery_counts_by_case(artery_type, counts, ax):\n",
    "    # Define the bins for the histogram - bins from 0 to 25, with an extra bin for values >25\n",
    "    bins = np.arange(28)\n",
    "    # Process counts to clip at 25\n",
    "    processed_counts = [min(x, 26) for x in counts]  # Values greater than 25 are set to 25\n",
    "    # Plot histogram with defined bins\n",
    "    ax.hist(processed_counts, bins=bins, alpha=0.5, color='blue')\n",
    "    # Labels for x-ticks, handling >25 as a special case\n",
    "    labels = [str(i) for i in range(26)] + ['>25']\n",
    "    # Set x-tick labels\n",
    "    bin_width = bins[1] - bins[0]\n",
    "    ax.set_xticks(np.arange(len(labels)) * bin_width + bin_width / 2)\n",
    "    ax.set_xticklabels(labels, fontsize=15)  # Set font size for x-ticks\n",
    "    ax.tick_params(axis='y', which='major', labelsize=15)  # Set font size for y-ticks\n",
    "\n",
    "    # Set axis labels and title with context-specific information\n",
    "    ax.set_xlabel(f'Count of {artery_type} per Whole Slide Image', fontsize=18)\n",
    "    ax.set_ylabel('Frequency of Slides', fontsize=18)\n",
    "    ax.set_title(f'Distribution of {artery_type} Across Slides', fontsize=20)\n",
    "\n",
    "doc.add_heading(f'Section 1: Data Overview', level=1)\n",
    "doc.add_paragraph(\n",
    "    f\"Initially, {len(pat_df)} slides were selected from the Neptune repository for this study, all of which have been either manually annotated \"\n",
    "    f\"or predicted through deep learning and subsequently quality controlled. However, due to issues such as poor staining quality, \"\n",
    "    f\"nephrectomy specimens, or the absence of arteries, {len(pat_df) - len(artery_counts_by_case['All Arteries'])} slides were discarded, leaving \"\n",
    "    f\"{len(artery_counts_by_case['All Arteries'])} for analysis.\"\n",
    ")\n",
    "doc.add_paragraph(\n",
    "    f\"In total, N={np.sum(artery_counts_by_case['Arterioles'])} arterioles, {np.sum(artery_counts_by_case['Interlobular Arteries'])} interlobular arteries, \"\n",
    "    f\"and {np.sum(artery_counts_by_case['Arcuate Arteries'])} arcuate arteries were segmented and visually scored (0-3) for arteriosclerosis and hyalinosis.\"\n",
    ")\n",
    "\n",
    "doc.add_heading('Histograms for Artery Counts', level=2)\n",
    "\n",
    "doc.add_paragraph(\n",
    "    \"This section presents the distribution of artery counts per slides. \"\n",
    "    \"Each histogram below represents the frequency of slides containing specific counts of each artery type.\"\n",
    ")\n",
    "\n",
    "for artery_type in ARTERY_TYPES:\n",
    "    counts = artery_counts_by_case[artery_type]\n",
    "    fig, ax = plt.subplots(figsize=(18, 5))  # Create a single subplot directly\n",
    "    plot_artery_counts_by_case(artery_type, counts, ax)\n",
    "    plot_filename = f\"{artery_type.replace(' ', '_')}_count_analysis.png\"\n",
    "    save_fig(fig, plot_filename)\n",
    "    doc.add_picture(plot_filename, width=Inches(6))\n",
    "    os.remove(plot_filename)  # Optional: remove the file after adding to the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116235/3007260293.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  severity_counts = combined_classifications.groupby(['Artery Type', f'{disease_type} Severity']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_116235/3007260293.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(ax.get_yticks(), fontsize=18)\n",
      "/tmp/ipykernel_116235/3007260293.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  severity_counts = combined_classifications.groupby(['Artery Type', f'{disease_type} Severity']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_116235/3007260293.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(ax.get_yticks(), fontsize=18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<docx.text.paragraph.Paragraph at 0x798c0d369100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of each severity level within each Artery Type\n",
    "def barplot(counts, col, ax):\n",
    "    # Plotting directly on the provided axis\n",
    "    counts.plot(kind='bar', ax=ax, legend=True)\n",
    "    ax.set_title(f'Distribution of {col} by Artery Type', fontsize=20)\n",
    "    ax.set_ylabel('Count', fontsize=15)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, fontsize=18)\n",
    "    ax.set_yticklabels(ax.get_yticks(), fontsize=18)\n",
    "    # Legend configuration\n",
    "    ax.legend(title=col, fontsize=15, title_fontsize=15)\n",
    "\n",
    "    # Annotating bars with their heights\n",
    "    max_height = max(counts.max())\n",
    "    ax.set_ylim(0, max_height * 1.1)  # Scale y-axis to fit annotations\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "doc.add_heading('Bar Charts for Severity Distributions', level=2)\n",
    "doc.add_paragraph(\n",
    "    \"The following figures illustrate the distribution of severity scores for Arteriosclerosis and Hyalinosis across different artery types. \"\n",
    ")\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "for i, disease_type in enumerate(DISEASE_TYPES):\n",
    "    # Calculate counts\n",
    "    severity_counts = combined_classifications.groupby(['Artery Type', f'{disease_type} Severity']).size().unstack(fill_value=0)\n",
    "    # Create the bar plot on the specified subplot\n",
    "    barplot(severity_counts, f'{disease_type} Severity', axs[i])\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plot_filename = \"disease_severity_distribution.png\"\n",
    "fig.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "# Assuming 'doc' is your Word document instance\n",
    "doc.add_picture(plot_filename, width=Inches(6))\n",
    "os.remove(plot_filename)  # Clean up the file after adding to the document\n",
    "doc.add_page_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_analysis(df, col, ax, title, color):\n",
    "    # Check if the data is continuous or discrete\n",
    "    # Assuming data is discrete if unique values are few and all are integers\n",
    "    data = df[col].dropna()\n",
    "    unique_values = np.sort(data.unique())\n",
    "    is_all_integers = all(value.is_integer() for value in unique_values)\n",
    "\n",
    "    is_continuous = len(unique_values) > 7 and not is_all_integers\n",
    "    \n",
    "    if is_continuous:\n",
    "        # Handle zeros separately if present\n",
    "        zero_count = (data == 0).sum()\n",
    "        non_zero_data = data[data != 0]\n",
    "        max_val = non_zero_data.max()\n",
    "        \n",
    "        bins = np.linspace(0, max_val, 6)  # Create bins between 0 and max_val\n",
    "        bins = np.insert(bins, 0, -np.finfo(float).eps)  # Start bins from zero\n",
    "\n",
    "        # Bin the data\n",
    "        data_binned = pd.cut(data, bins=bins, include_lowest=True, right=True)\n",
    "        counts = data_binned.value_counts().sort_index()\n",
    "\n",
    "        # Create labels for bins\n",
    "        labels = ['0'] if zero_count > 0 else []  # Label for zero\n",
    "        labels += [f\"({bins[i]:.2f}, {bins[i+1]:.2f}]\" for i in range(1, len(bins)-1)]\n",
    "\n",
    "        # Plot the counts\n",
    "        counts.plot(kind='bar', ax=ax, color=color, alpha=0.75)\n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=45)  # Rotate labels for better visibility\n",
    "    else:\n",
    "        if is_all_integers:\n",
    "            unique_values = unique_values.astype(int)\n",
    "        # Use bar chart for discrete data\n",
    "        counts = data.value_counts().sort_index()\n",
    "        counts.plot(kind='bar', ax=ax, color=color, alpha=0.75)\n",
    "        ax.set_xticks(range(len(unique_values)))\n",
    "        ax.set_xticklabels(unique_values, rotation=0)\n",
    "\n",
    "    \n",
    "    # Setting the labels and titles\n",
    "    ax.set_xlabel('Severity Score', fontsize=15)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_ylabel('Count', fontsize=15)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "\n",
    "    # Annotate bars with counts\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(int(p.get_height())), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "def add_distribution_analysis_to_doc(doc, combined_classifications, pat_df_selected, \n",
    "                                     artery_type, disease_type, agg_metric, severity_column):\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    distribution_analysis(combined_classifications.loc[combined_classifications[\"Artery Type\"] == artery_type], \n",
    "                            f'{disease_type} Severity', ax1, f'{artery_type} Count by Severity', '#87CEEB')\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    distribution_analysis(pat_df_selected, severity_column, ax2, \"Case Count by Severity\", \"#F88379\")\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    distribution_analysis(pat_df_selected.loc[pat_df_selected['ESRDorEGFR40BX_LR'] == 1, :], \n",
    "                            severity_column, ax3, \"Event Count by Severity\", \"#D8BFD8\")\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plot_filename = f\"{artery_type.replace(' ', '_')}_{disease_type}_{agg_metric}_analysis.png\"\n",
    "    save_fig(fig, plot_filename)\n",
    "    doc.add_picture(plot_filename, width=Inches(6))\n",
    "    os.remove(plot_filename)\n",
    "\n",
    "\n",
    "# pat_df['DaysBXtoESRDorEGFR40_LR'] = pd.to_numeric(pat_df['DaysBXtoESRDorEGFR40_LR'], errors='coerce')\n",
    "pat_df['ESRDorEGFR40BX_LR'] = pat_df['ESRDorEGFR40BX_LR'].map({'1: Yes': 1, '0: No': 0}).astype(int)\n",
    "\n",
    "# Iterate over artery types\n",
    "for sec_num, artery_type in enumerate(ARTERY_TYPES):\n",
    "    doc.add_heading(f'Section {sec_num + 2}: {artery_type}', level=1)\n",
    "    counts = artery_counts_by_case[artery_type]\n",
    "    doc.add_paragraph(f\"{np.sum(counts)} {artery_type} extracted from {np.sum(np.array(counts)>0)} slides. \"\n",
    "                      f\"We already have {artery_type}-level scores, and we need to aggregate to the case level. \"\n",
    "                      \"We investigate multiple aggregation metrics and their survival analysis impact.\")\n",
    "\n",
    "    for sub_sec_num, agg_metric in enumerate([\"Max\", \"Median\", \"75th\", \"Mean\", \"NonZeroPct\"]):\n",
    "        doc.add_heading(f'Section {sec_num+2}.{sub_sec_num+1}: {artery_type}, Aggregated by {agg_metric}', level=2)\n",
    "        for sub_sub_sec_num, disease_type in enumerate([\"Arteriosclerosis\", \"Hyalinosis\"]):\n",
    "            doc.add_heading(f'{disease_type}', level=3)\n",
    "            severity_column = f\"{agg_metric}_{disease_type}_Severity\" if artery_type == 'All Arteries' else \\\n",
    "                \"_\".join([agg_metric, disease_type, \"Severity\", \"in\", artery_type.replace(\" \", \"_\")])\n",
    "            pat_df_selected = pat_df.loc[pat_df[severity_column].notna() & (pat_df[severity_column] >= 0), :].copy()\n",
    "            add_distribution_analysis_to_doc(doc, combined_classifications, pat_df_selected, \n",
    "                                             artery_type, disease_type, agg_metric, severity_column)\n",
    "            \n",
    "            thresholds = [0]\n",
    "            if agg_metric == \"Max\":\n",
    "                thresholds += [1, 2]\n",
    "            else:\n",
    "                non_zero_vals = pat_df_selected[severity_column][pat_df_selected[severity_column] > 0]\n",
    "                if len(non_zero_vals) != 0: \n",
    "                    thresholds += [np.percentile(non_zero_vals, 25), np.median(non_zero_vals)]\n",
    "\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(22, 6))\n",
    "            for i, th in enumerate(thresholds):\n",
    "                if agg_metric == \"Max\":\n",
    "                    label_1 = f\"≤{int(th)}\"\n",
    "                    label_2 = f\">{int(th)}\"\n",
    "                else:\n",
    "                    percentile_label = \"25th\" if i == 1 else \"median\" if i == 2 else \"0\"\n",
    "                    label_1 = f\"≤ {percentile_label} ({th:.2f})\"\n",
    "                    label_2 = f\"> {percentile_label} ({th:.2f})\"\n",
    "\n",
    "                groups = [(label_1, pat_df_selected[pat_df_selected[severity_column] <= th]),\n",
    "                        (label_2, pat_df_selected[pat_df_selected[severity_column] > th])]\n",
    "                survival_analysis(groups, axs[i])\n",
    "                if i == 0:\n",
    "                    axs[i].set_ylabel('Survival Probability', fontsize=15)\n",
    "            plt.tight_layout()\n",
    "            plot_filename = f\"{artery_type.replace(' ', '_')}_{disease_type}_{agg_metric}_survival.png\"\n",
    "            save_fig(fig, plot_filename)\n",
    "            doc.add_picture(plot_filename, width=Inches(6))\n",
    "            os.remove(plot_filename)\n",
    "    doc.add_page_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gallery_view(images, titles, cols=5):\n",
    "    # Number of images to show per page/view\n",
    "    num_images = len(images)\n",
    "    rows_per_view = 1  # Show one row at a time\n",
    "\n",
    "    # Calculate the number of views needed\n",
    "    total_views = (num_images + cols - 1) // cols\n",
    "    plot_filenames = []  # To keep track of saved image file paths\n",
    "\n",
    "    for view in range(total_views):\n",
    "        start_index = view * cols\n",
    "        end_index = min(start_index + cols, num_images)\n",
    "        fig, axs = plt.subplots(rows_per_view, cols, figsize=(15, 5 * rows_per_view))\n",
    "        axs = axs.ravel()\n",
    "        for i in range(cols):\n",
    "            index = start_index + i\n",
    "            if index < end_index:\n",
    "                image = images[index]\n",
    "                # Rotate image if width is greater than height\n",
    "                if image.shape[1] > image.shape[0]:  # image.shape gives (height, width, channels)\n",
    "                    image = np.rot90(image)  # Rotate 90 degrees\n",
    "                axs[i].imshow(image)\n",
    "                axs[i].set_title(titles[index], fontsize=18)\n",
    "                axs[i].axis('off')\n",
    "            else:\n",
    "                axs[i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        # Save the figure to file\n",
    "        plot_filename = f\"gallery_view_{view}.png\"\n",
    "        save_fig(fig, plot_filename)\n",
    "        plot_filenames.append(plot_filename)\n",
    "    return plot_filenames\n",
    "\n",
    "\n",
    "def load_images_for_type(artery_type, severity_column):\n",
    "    images = []\n",
    "    titles = []\n",
    "    # Ensure combined_classifications DataFrame is defined correctly with the right columns\n",
    "    for index, row in combined_classifications.loc[\n",
    "        (combined_classifications[\"Artery Type\"] == artery_type) &\n",
    "        (combined_classifications[severity_column] > 0), :\n",
    "    ].iterrows():\n",
    "        # Construct the path to the image file\n",
    "        image_path = os.path.join(CROPPED_VESSELS_DIR, artery_type, \n",
    "                                  row[\"Image Name\"].replace(\".png\", \"_w_ann.png\"))\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Correct function to load the image\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n",
    "            images.append(img)\n",
    "            # Create a title using multiple fields from the DataFrame\n",
    "            title = f\"B{row['Image Name'].split('_')[1]}{row['Artery ID']}-AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "            titles.append(title)\n",
    "    return images, titles\n",
    "\n",
    "doc.add_heading(f'Appendix', level=1)\n",
    "# Implementation in the document creation process\n",
    "for artery_type, severity_column in [\n",
    "    (\"Arterioles\", \"Arteriosclerosis Severity\"),\n",
    "    (\"Arcuate Arteries\", \"Hyalinosis Severity\"),\n",
    "    (\"Interlobular Arteries\", \"Hyalinosis Severity\")\n",
    "]:\n",
    "    doc.add_heading(f\"{artery_type} with {severity_column} > 0\", level=2)\n",
    "    images, titles = load_images_for_type(artery_type, severity_column)\n",
    "    plot_filenames = gallery_view(images, titles)\n",
    "    for plot_filename in plot_filenames:\n",
    "        doc.add_picture(plot_filename, width=Inches(6))\n",
    "        os.remove(plot_filename)\n",
    "    doc.add_page_break()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save(ANALYSIS_DOC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_df_selected = pat_df.loc[\n",
    "#      (pat_df[\"Max_Arteriosclerosis_Severity_in_Interlobular_Arteries\"] >= 0) &\n",
    "#      (pat_df[\"Max_Arteriosclerosis_Severity_in_Arcuate_Arteries\"] >= 0)\n",
    "# ].copy()\n",
    "# doc.add_paragraph(\n",
    "#         f\"{len(pat_df_selected)} cases have both Interlobular and Arcuate present. \"\n",
    "#     )\n",
    "# print(pat_df_selected.shape)\n",
    "# pat_df_selected = pat_df_selected.loc[\n",
    "#      (pat_df_selected[\"Max_Arteriosclerosis_Severity_in_Interlobular_Arteries\"] > 0) |\n",
    "#      (pat_df_selected[\"Max_Arteriosclerosis_Severity_in_Arcuate_Arteries\"] > 0)\n",
    "# ]\n",
    "# doc.add_paragraph(f\"{len(pat_df_selected)} cases have at least one artery type with arteriosclerosis severity greater than 0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Assuming pat_df_selected is already filtered as required\n",
    "# fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "# # Generate x values with a slight offset to prevent overlapping\n",
    "# x_interlobular = np.arange(len(pat_df_selected)) \n",
    "# x_arcuate = np.arange(len(pat_df_selected)) \n",
    "\n",
    "# plt.scatter(x_interlobular, pat_df_selected['Max_Arteriosclerosis_Severity_in_Interlobular_Arteries'],\n",
    "#             color='blue', alpha=0.6, edgecolor='black', marker='s', label='Interlobular Arteries')\n",
    "\n",
    "# plt.scatter(x_arcuate, pat_df_selected['Max_Arteriosclerosis_Severity_in_Arcuate_Arteries'],\n",
    "#             color='red', alpha=0.6, edgecolor='black', marker='^', label='Arcuate Arteries')\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Index of Cases', fontsize=16)\n",
    "# plt.ylabel('Max Arteriosclerosis Severity', fontsize=16)\n",
    "# plt.title('Comparison of Arteriosclerosis Severity Between Artery Types', fontsize=18)\n",
    "\n",
    "# # Explicitly set y-ticks to be only integers 0, 1, 2, 3\n",
    "# plt.yticks([0, 1, 2, 3])\n",
    "# plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# # Add a legend\n",
    "# plt.legend()\n",
    "\n",
    "# # Add grid for better readability\n",
    "# plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# plot_filename = f\"comparison.png\"\n",
    "# save_fig(fig, plot_filename)\n",
    "# doc.add_picture(plot_filename, width=Inches(6))\n",
    "# os.remove(plot_filename)  # Optional: remove the file after adding to the document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count where Interlobular severity is greater than Arcuate severity\n",
    "# count_greater = (pat_df_selected['Max_Arteriosclerosis_Severity_in_Interlobular_Arteries'] >\n",
    "#                  pat_df_selected['Max_Arteriosclerosis_Severity_in_Arcuate_Arteries']).sum()\n",
    "\n",
    "# # Count where Interlobular severity is less than Arcuate severity\n",
    "# count_less = (pat_df_selected['Max_Arteriosclerosis_Severity_in_Interlobular_Arteries'] <\n",
    "#               pat_df_selected['Max_Arteriosclerosis_Severity_in_Arcuate_Arteries']).sum()\n",
    "\n",
    "# # Optionally, count where Interlobular severity is equal to Arcuate severity\n",
    "# count_equal = (pat_df_selected['Max_Arteriosclerosis_Severity_in_Interlobular_Arteries'] ==\n",
    "#                pat_df_selected['Max_Arteriosclerosis_Severity_in_Arcuate_Arteries']).sum()\n",
    "\n",
    "# doc.add_paragraph(\n",
    "#         f\"Number of cases where Interlobular severity > Arcuate severity: {count_greater}. \"\n",
    "#     )\n",
    "# doc.add_paragraph(\n",
    "#         f\"Number of cases where Interlobular severity < Arcuate severity: {count_less}. \"\n",
    "#     )\n",
    "# # Print the results\n",
    "# print(\"Number of cases where Interlobular severity > Arcuate severity:\", count_greater)\n",
    "# print(\"Number of cases where Interlobular severity < Arcuate severity:\", count_less)\n",
    "# print(\"Number of cases where Interlobular severity = Arcuate severity:\", count_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
