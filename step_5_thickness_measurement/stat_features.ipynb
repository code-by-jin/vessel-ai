{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Local module imports\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.utils_post_process import post_process\n",
    "from utils.utils_vis import save_image, plot_artery_ann\n",
    "from utils.utils_data import get_classifications, get_segmentations, get_measurements\n",
    "from utils.utils_geometry import get_contours, is_contour_intersecting_or_within\n",
    "from utils.utils_measure import measure_thickness\n",
    "from utils.utils_constants import (VESSEL_NEPTUNE_PAT_INFO_PATH as VESSEL_PAT_INFO_PATH, \n",
    "                                   CLASSIFICATION_PATH, SEGMENTATION_DIR,\n",
    "                                   MEASUREMENTS_DIR, FEATURES_PATH, CROPPED_VESSELS_COMBINED_DIR)\n",
    "from utils.utils_feature import extract_features\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_base_features(cnt_outer, cnts_middle, cnts_inner, cnts_hys):\n",
    "    artery_area = cv2.contourArea(cnt_outer)\n",
    "    lumen_area = sum(cv2.contourArea(contour) for contour in cnts_inner)\n",
    "    intima_area = sum(cv2.contourArea(contour) for contour in cnts_middle) - lumen_area\n",
    "    media_area = artery_area - lumen_area - intima_area\n",
    "    hys_area = sum(cv2.contourArea(contour) for contour in cnts_hys)\n",
    "\n",
    "    base_features = {\n",
    "        'Area_Media': media_area,\n",
    "        'Area_Intima': intima_area,\n",
    "        'Area_Lumen': lumen_area,\n",
    "        'Area_Hys': hys_area\n",
    "    }\n",
    "    return base_features\n",
    "\n",
    "def extract_measurement_features(measurements_vessel, artery_area):\n",
    "    # Initialize arrays for ratio calculations\n",
    "    all_media = []\n",
    "    all_intima = []\n",
    "    all_ratio = []\n",
    "    # Iterate over each row in the measurement DataFrame\n",
    "    for m in measurements_vessel:\n",
    "        m_media = np.array(m[\"Thickness_Media\"])\n",
    "        m_intima = np.array(m[\"Thickness_Intima\"])\n",
    "\n",
    "        # Example processing assuming m_media and m_intima are arrays\n",
    "        m_wall = np.array([x + y if x >= 0 else x for x, y in zip(m_media, m_intima)])\n",
    "\n",
    "        m_media, m_intima, m_ratio = post_process(m_media, m_intima, m_wall,\n",
    "                                                  t_multi=15, t_open_lumen=30, t_mediam=15, t_average=15, \n",
    "                                                  artery_area=artery_area)\n",
    "        all_media.extend(m_media)\n",
    "        all_intima.extend(m_intima)\n",
    "        all_ratio.extend(m_ratio)\n",
    "\n",
    "    # Assuming all_media and all_intima are lists of arrays, we concatenate them to perform a global calculation\n",
    "    features_intima, features_media, features_ratio = extract_features(all_media, all_intima, all_ratio)\n",
    "    return {**features_intima, **features_media, **features_ratio}\n",
    "\n",
    "\n",
    "def extract_features_slide(classifications, segmentations, measurements, slide_basename):\n",
    "    slide_features = []\n",
    "    for _, row in classifications.iterrows():\n",
    "        img_name = row[\"Image Name\"]\n",
    "        bbox_x, bbox_y, bbox_width, bbox_height = map(int, row[\"Bounding Box\"].split(\",\"))  \n",
    "        cnt_outer, cnts_middle, cnts_inner, cnts_hys = get_contours(segmentations, slide_basename, img_name,\n",
    "                                                                    bbox_x, bbox_y, bbox_width, bbox_height)\n",
    "        base_features = extract_base_features(cnt_outer, cnts_middle, cnts_inner, cnts_hys)\n",
    "\n",
    "        measurements_vessel = measurements[img_name]\n",
    "        if len(measurements_vessel) == 0:\n",
    "            logging.warning(\n",
    "                    f\"No measurements for image {img_name} in slide {slide_basename}.\"\n",
    "                    )\n",
    "            measurement_features = {}\n",
    "        else:\n",
    "            measurement_features = extract_measurement_features(measurements_vessel, cv2.contourArea(cnt_outer))\n",
    "\n",
    "        slide_features.append({**{\"Slide Name\": slide_basename}, **row.to_dict(), **base_features, **measurement_features})\n",
    "    return slide_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 03:46:36,257 - INFO - 247 slides selected, 15 discarded, 232 left for analysis.\n",
      "2024-07-16 03:46:36,276 - INFO - Processing: 2/247: 11_26609_000_009_L2_TRI.svs\n",
      "2024-07-16 03:46:36,925 - WARNING - No measurements for 11_26609_000_009_L2_TRI in image Biopsy_002_WSI_001_A17_90117_24688_260_389.png.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pat_df = pd.read_csv(VESSEL_PAT_INFO_PATH)\n",
    "suffix = \"_measurements\"\n",
    "\n",
    "available_sheetnames = pd.ExcelFile(CLASSIFICATION_PATH).sheet_names\n",
    "logging.info(f\"{len(pat_df)} slides selected, {len(pat_df) - len(available_sheetnames)} discarded, \" \n",
    "             f\"{len(available_sheetnames)} left for analysis.\")\n",
    "\n",
    "excel_writer = pd.ExcelWriter(FEATURES_PATH, engine='xlsxwriter')\n",
    "\n",
    "collected_features = []\n",
    "for i, slide_filename in enumerate(pat_df[\"WSI_Selected\"]):\n",
    "    if slide_filename != \"11_26609_000_009_L2_TRI.svs\":continue\n",
    "    logging.info(f\"Processing: {i+1}/{len(pat_df)}: {slide_filename}\")\n",
    "    slide_basename = os.path.splitext(slide_filename)[0]\n",
    "\n",
    "    classifications = get_classifications(CLASSIFICATION_PATH, slide_basename, available_sheetnames, remove_others=False)\n",
    "    if classifications.empty:\n",
    "        continue  # Skip to if no relevant data\n",
    "\n",
    "    segmentations_path = os.path.join(SEGMENTATION_DIR, f\"{slide_basename}.geojson\")\n",
    "    segmentations = get_segmentations(segmentations_path, clean=True)\n",
    "\n",
    "    measurements_path = os.path.join(MEASUREMENTS_DIR, f\"{slide_basename}{suffix}.json\")\n",
    "    measurements = get_measurements(measurements_path, clean=True)\n",
    "    slide_features = extract_features_slide(classifications, segmentations, measurements, slide_basename)\n",
    "    collected_features.extend(slide_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
