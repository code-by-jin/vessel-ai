{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Local module imports\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.utils_data import get_veesel_sheets, get_measurements\n",
    "from utils.utils_constants import (VESSEL_NEPTUNE_PAT_INFO_W_SCORE_PATH as  VESSEL_PAT_INFO_W_SCORE_PATH,\n",
    "                                   VESSEL_NEPTUNE_PAT_INFO_W_SCORE_W_FEATURE_PATH as  VESSEL_PAT_INFO_W_SCORE_W_FEATURE_PATH,\n",
    "                                   DISEASE_TYPES, ARTERY_TYPES, CLASSIFICATION_SEVERITY_MAPPING,\n",
    "                                   MEASUREMENTS_DIR, FEATURES_PATH, CROPPED_VESSELS_DIR)\n",
    "\n",
    "from utils.utils_vis import gallery_view\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature_names = [\n",
    "'Media Area Ratio', 'Intima Area Ratio', 'Lumen Area Ratio'\n",
    "]\n",
    "measurement_feature_names = [\n",
    "                 'Intima Average', 'Intima Median', 'Intima Variance', 'Intima Peak Height', 'Intima Peak Prominence', \n",
    "                 'Media Average', 'Media Median', 'Media Variance', 'Media Peak Height', 'Media Peak Prominence', \n",
    "                 'Ratio Average', 'Ratio Median', 'Ratio Variance', 'Ratio Peak Height', 'Ratio Peak Prominence']\n",
    "\n",
    "hya_feature_names = [\n",
    "'Hyalinosis Area Ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin_plots(df, feature_name, severity_type, ax, artery_type):\n",
    "    features = df.loc[:, feature_name]\n",
    "    scores = df.loc[:, f'{severity_type} Severity']\n",
    "    rho, p_val = scipy.stats.pearsonr(features, scores)\n",
    "    p_str = f\"p<0.001\" if p_val < 0.001 else f\"p={p_val:.3f}\"\n",
    "    sns.violinplot(x=f'{severity_type} Severity', y=feature_name, data=df, ax=ax)\n",
    "    # if \"Ratio\" in feature_name: \n",
    "    #     feature_name = feature_name.replace(\"Ratio\", \"Intima-Media Ratio\")\n",
    "    # ax.set_xlabel(feature_name, fontsize=20)\n",
    "    ax.set_ylabel(f\"{feature_name}\", fontsize=20)\n",
    "    ax.set_title(f\"{artery_type}\\n$\\\\gamma_{{\\\\rho}}$={rho:.2f} {p_str}\", y=-0.4, pad=-14, fontsize=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_measurements_exclude_hya_manual\"\n",
    "collected_features = pd.read_csv(FEATURES_PATH.replace(\".xlsx\", f\"{suffix}.csv\"))\n",
    "collected_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artery_type = \"Arcuate Arteries\"\n",
    "disease_type = \"Arteriosclerosis\"\n",
    "feature_names = ['Lumen Area Ratio', 'Intima Peak Height', 'Ratio Peak Height']\n",
    "collected_features_selected = collected_features.loc[(collected_features[\"Artery Type\"] == artery_type)]\n",
    "collected_features_selected = collected_features_selected.dropna(subset=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Assuming collected_features_selected is ready and contains the correct columns\n",
    "# X = collected_features_selected[feature_names]\n",
    "# y = collected_features_selected[disease_type + \" Severity\"]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Build a Random Forest model\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # Visualize feature importance\n",
    "# # feature_importances = pd.Series(model.feature_importances_, index=feature_names)\n",
    "# # sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "# # plt.title('Feature Importance')\n",
    "# # plt.show()\n",
    "\n",
    "# # Plot predicted vs actual\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "# plt.xlabel('Actual Labels')\n",
    "# plt.ylabel('Predicted Labels')\n",
    "# plt.title('Predicted vs Actual Severity')\n",
    "# plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "# print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = collected_features[(collected_features[\"Arteriosclerosis Severity\"] == 0)\n",
    "#                    & (collected_features[\"Ratio Average\"] > 0.4)\n",
    "#                 #    & (collected_features[\"Intima Variance\"] > 0.002)\n",
    "#                    & (collected_features[\"Artery Type\"] == \"Interlobular Arteries\")]\n",
    "\n",
    "# images, titles = [], []\n",
    "# # Ensure combined_classifications DataFrame is defined correctly with the right columns\n",
    "# for index, row in rows.iterrows():\n",
    "#     artery_type = row[\"Artery Type\"]\n",
    "#     # Construct the path to the image file\n",
    "#     image_path = os.path.join(CROPPED_VESSELS_DIR, artery_type, \n",
    "#                                 row[\"Image Name\"].replace(\".png\", \"_w_ann.png\"))\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Correct function to load the image\n",
    "#     if img is not None:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n",
    "#         images.append(img)\n",
    "#         # Create a title using multiple fields from the DataFrame\n",
    "#         title = f\"B{row['Image Name'].split('_')[1]}{row['Artery ID']}-AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "#         # Peak: {row['Intima Peak Height']}\"\n",
    "#         titles.append(title)\n",
    "\n",
    "# # collected_features = collected_features.dropna()\n",
    "# gallery_view(images, titles, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard = [\"Biopsy_039_WSI_001_A12_34475_15494_1002_852.png\",\n",
    "           \"Biopsy_167_WSI_001_A12_123358_53578_920_1202.png\",\n",
    "           \"Biopsy_221_WSI_001_A03_13753_61887_780_908.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# artery_type = \"Arterioles\"\n",
    "for artery_type in ARTERY_TYPES:\n",
    "    print(artery_type)\n",
    "    disease_type = \"Arteriosclerosis\"\n",
    "    feature_names = ['Intima Average', 'Intima Peak Height', 'Media Average', 'Media Peak Height', \n",
    "                    'Ratio Average', 'Ratio Peak Height']\n",
    "    collected_features_selected = collected_features.loc[(collected_features[\"Artery Type\"] == artery_type)\n",
    "                                                        #  &(collected_features[\"Hyalinosis Severity\"] == 0)\n",
    "                                                        ]\n",
    "    print(collected_features_selected.shape)\n",
    "    collected_features_selected = collected_features_selected.dropna(subset=feature_names)\n",
    "    print(collected_features_selected.shape)\n",
    "    # collected_features_selected = collected_features_selected[~collected_features_selected[\"Image Name\"].isin(discard)]\n",
    "    # print(collected_features_selected.shape)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(25, 5))\n",
    "    for i, measure_src in enumerate([\"Intima\", \"Media\", \"Ratio\"]):\n",
    "        for j, stat_f in enumerate([\"Average\", \"Peak Height\"]):\n",
    "            feature_name = f\"{measure_src} {stat_f}\"\n",
    "            violin_plots(collected_features_selected, feature_name, disease_type, axs[i*2+j], artery_type)  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 3, figsize=(5*3, 5))  \n",
    "# for i, artery_type in enumerate(ARTERY_TYPES):\n",
    "#     violin_plots(collected_features.loc[collected_features[\"Artery Type\"]==artery_type, :], \n",
    "#                  collected_features.loc[collected_features[\"Hyalinosis Severity\"]==0, :],\n",
    "#                  \"Hyalinosis Area Ratio\", \"Hyalinosis\", axs[i], artery_type)  \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have already defined 'collected_features'\n",
    "# # Specify the columns to check for NaNs\n",
    "# columns_to_check = [\n",
    "#     'Intima Average', 'Intima Median', 'Intima Variance',\n",
    "#     'Vis Intima Peak Indice', 'Intima Peak Height',\n",
    "#     'Intima Peak Prominence', 'Media Average', 'Media Median',\n",
    "#     'Media Variance', 'Vis Media Peak Indice', 'Media Peak Height',\n",
    "#     'Media Peak Prominence', 'Ratio Average', 'Ratio Median',\n",
    "#     'Ratio Variance', 'Vis Ratio Peak Indice', 'Ratio Peak Height',\n",
    "#     'Ratio Peak Prominence'\n",
    "# ]\n",
    "\n",
    "# # This will select the rows from collected_features where all columns in columns_to_check are NaN\n",
    "# # rows_all_nan = collected_features[collected_features[columns_to_check].isna().all(axis=1)]\n",
    "\n",
    "# # Create a boolean mask where at least one column is NaN\n",
    "# at_least_one_nan = collected_features[columns_to_check].isna().any(axis=1)\n",
    "\n",
    "# # Create a boolean mask where not all columns are NaN\n",
    "# not_all_nan = ~collected_features[columns_to_check].isna().all(axis=1)\n",
    "\n",
    "# # Combine both masks to filter rows\n",
    "# rows_with_some_nans = collected_features[at_least_one_nan & not_all_nan]\n",
    "\n",
    "\n",
    "# images, titles = [], []\n",
    "# # Ensure combined_classifications DataFrame is defined correctly with the right columns\n",
    "# for index, row in rows_with_some_nans.iterrows():\n",
    "#     artery_type = row[\"Artery Type\"]\n",
    "#     # Construct the path to the image file\n",
    "#     image_path = os.path.join(CROPPED_VESSELS_DIR, artery_type, \n",
    "#                                 row[\"Image Name\"].replace(\".png\", \"_w_ann.png\"))\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Correct function to load the image\n",
    "#     if img is not None:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n",
    "#         images.append(img)\n",
    "#         # Create a title using multiple fields from the DataFrame\n",
    "#         title = f\"B{row['Image Name'].split('_')[1]}{row['Artery ID']}-AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "#         titles.append(title)\n",
    "\n",
    "# # collected_features = collected_features.dropna()\n",
    "# gallery_view(images, titles, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_with_nan = collected_features[collected_features.isna().any(axis=1)]\n",
    "# images, titles = [], []\n",
    "# # Ensure combined_classifications DataFrame is defined correctly with the right columns\n",
    "# for index, row in rows_with_nan.iterrows():\n",
    "#     artery_type = row[\"Artery Type\"]\n",
    "#     # Construct the path to the image file\n",
    "#     image_path = os.path.join(CROPPED_VESSELS_DIR, artery_type, \n",
    "#                                 row[\"Image Name\"].replace(\".png\", \"_w_ann.png\"))\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Correct function to load the image\n",
    "#     if img is not None:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n",
    "#         images.append(img)\n",
    "#         # Create a title using multiple fields from the DataFrame\n",
    "#         title = f\"B{row['Image Name'].split('_')[1]}{row['Artery ID']}-AS: {row['Arteriosclerosis Severity']}; HS: {row['Hyalinosis Severity']}\"\n",
    "#         titles.append(title)\n",
    "\n",
    "# collected_features = collected_features.dropna()\n",
    "# collected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gallery_view(images, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature_names = ['Intima Average', 'Intima Peak Height', 'Ratio Average', 'Ratio Peak Height']\n",
    "# for artery_type in ARTERY_TYPES:\n",
    "#     for disease_type in DISEASE_TYPES:\n",
    "#         if disease_type != \"Arteriosclerosis\": continue\n",
    "#         fig, axs = plt.subplots(1, len(feature_names), figsize=(5*len(feature_names), 5))  \n",
    "#         for i, feature_name in enumerate(feature_names):\n",
    "#             violin_plots(collected_features.loc[collected_features[\"Artery Type\"]==artery_type, :], \n",
    "#                          feature_name, disease_type, axs[i])  \n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.read_csv(VESSEL_PAT_INFO_W_SCORE_PATH)\n",
    "feature_path = FEATURES_PATH.replace(\".xlsx\", f\"{suffix}.xlsx\")\n",
    "\n",
    "agg_feature_path = VESSEL_PAT_INFO_W_SCORE_W_FEATURE_PATH.replace(\".csv\", f\"{suffix}.csv\")\n",
    "\n",
    "available_sheetnames = pd.ExcelFile(feature_path, engine='openpyxl').sheet_names\n",
    "logging.info(f\"{len(pat_df)} slides selected, {len(pat_df) - len(available_sheetnames)} discarded, \" \n",
    "            f\"{len(available_sheetnames)} left for analysis.\")\n",
    "\n",
    "\n",
    "for i, (index, row) in enumerate(pat_df.iterrows()):\n",
    "    slide_filename = row[\"WSI_Selected\"]\n",
    "    logging.info(f\"Processing: {i+1}/{len(pat_df)}: {slide_filename}\")\n",
    "    slide_basename = os.path.splitext(slide_filename)[0]\n",
    "   \n",
    "    features = get_veesel_sheets(feature_path, slide_basename, available_sheetnames, remove_others=True)\n",
    "    if features.empty:\n",
    "        continue  # Skip to if no relevant data\n",
    "\n",
    "    measurements_path = os.path.join(MEASUREMENTS_DIR, f\"{slide_basename}{suffix}.json\")\n",
    "    measurements = get_measurements(measurements_path, clean=True)\n",
    "\n",
    "    for disease_type in DISEASE_TYPES:\n",
    "        features[f\"{disease_type} Severity\"] = features[f\"{disease_type} Severity\"].map(CLASSIFICATION_SEVERITY_MAPPING)\n",
    "\n",
    "    for artery_type in ARTERY_TYPES:\n",
    "        for feature_name in base_feature_names + measurement_feature_names:\n",
    "            features_series = features[(features['Artery Type'] == artery_type)][feature_name]\n",
    "            if not features_series.empty:            \n",
    "                max_severity = features_series.max()\n",
    "                mean_severity = features_series.mean()\n",
    "                median_severity = features_series.median()\n",
    "                percentile_75th = features_series.quantile(0.75)\n",
    "                percentile_25th = features_series.quantile(0.25)\n",
    "            else:\n",
    "                max_severity = mean_severity = median_severity = percentile_75th = percentile_25th =  None  # or another indicator for no data\n",
    "\n",
    "            # Storing these values in the DataFrame\n",
    "            pat_df.loc[index, f'Max_{feature_name}_in_{artery_type}'.replace(\" \", \"_\")] = max_severity\n",
    "            pat_df.loc[index, f'Mean_{feature_name}_in_{artery_type}'.replace(\" \", \"_\")] = mean_severity\n",
    "            pat_df.loc[index, f'Median_{feature_name}_in_{artery_type}'.replace(\" \", \"_\")] = median_severity\n",
    "            pat_df.loc[index, f'75th_{feature_name}_in_{artery_type}'.replace(\" \", \"_\")] = percentile_75th\n",
    "            pat_df.loc[index, f'25th_{feature_name}_in_{artery_type}'.replace(\" \", \"_\")] = percentile_25th\n",
    "\n",
    "pat_df.to_csv(agg_feature_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
